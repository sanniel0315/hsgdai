import datetime
import time
import os
import tarfile
import csv
import json
import re # åŒ¯å…¥ re æ¨¡çµ„ä¾†è§£ææª”å
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from concurrent.futures import ThreadPoolExecutor, as_completed

# ====== è¨­å®š ======
IPS = [
    "10.161.74.50", "10.161.74.51", "10.161.74.52", "10.161.74.53",
    "10.161.74.54", "10.161.74.55", "10.161.74.56", "10.161.74.57",
    "10.161.74.58", "10.161.74.59", "10.161.74.60", "10.161.74.61",
]
MAX_WORKERS = 2

USERNAME = "admin"
PASSWORD = "PiXoRd168"
DOWNLOAD_DIR = r"C:\Users\AIVT-LPR\Downloads\aidata_downloads"
CHROMEDRIVER_PATH = os.path.join(os.path.dirname(__file__), 'drivers', 'chromedriver.exe')

# ====== æ—¥æœŸå®šç¾© ======
run_date = datetime.date.today()
data_date = run_date - datetime.timedelta(days=1)
run_date_str = run_date.strftime("%Y%m%d")
data_date_str_for_filter = data_date.strftime("%Y-%m-%d")
data_date_str_for_filename = data_date.strftime("%Y-%m-%d")

# ====== è¼‰å…¥è¨­å‚™åµæ¸¬è¨­å®š ======
try:
    with open(os.path.join(os.path.dirname(__file__), "device_config.json"), encoding="utf-8") as f:
        DEVICE_CONFIG = json.load(f)
except FileNotFoundError:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° device_config.json è¨­å®šæª”ï¼")
    DEVICE_CONFIG = {}

os.makedirs(DOWNLOAD_DIR, exist_ok=True)

def setup_driver():
    """è¨­å®šä¸¦å›å‚³ä¸€å€‹ Chrome driver instance"""
    chrome_options = Options()
    chrome_options.add_experimental_option("prefs", {"download.default_directory": DOWNLOAD_DIR})
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--ignore-certificate-errors")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--log-level=3")
    service = Service(CHROMEDRIVER_PATH)
    return webdriver.Chrome(service=service, options=chrome_options)

def process_logs(folder, ip, target_date_str, target_filename_date_str):
    """è§£ææ—¥èªŒæª”æ¡ˆï¼Œè™•ç†æ‰€æœ‰æ‰¾åˆ°çš„æª¢æ¸¬çµæœã€‚"""
    print(f"ğŸ”· [{ip}] é–‹å§‹è§£æ {target_date_str} çš„è³‡æ–™â€¦")
    # ... æ­¤å‡½å¼å…§å®¹èˆ‡å‰ä¸€ç‰ˆå®Œå…¨ç›¸åŒï¼Œæ­¤è™•çœç•¥ä»¥ä¿æŒç°¡æ½” ...
    # (è«‹åƒè€ƒå‰ä¸€å›ç­”ä¸­çš„å®Œæ•´ process_logs å‡½å¼å…§å®¹)
    for root, _, files in os.walk(folder):
        for fname in files:
            if not fname.lower().endswith(".txt"):
                continue
            
            inp = os.path.join(root, fname)
            try:
                with open(inp, 'r', encoding="utf-8") as fin:
                    first_line = fin.readline().strip()
                    if not first_line: continue
                    device_name = first_line.split("~")[0]
                
                out_csv = os.path.join(root, f"data_{device_name}_{target_filename_date_str}_clean.csv")
                out_txt = os.path.join(root, f"data_{device_name}_{target_filename_date_str}_original.txt")

                processed_lines = 0
                with open(inp, 'r', encoding="utf-8") as fin, \
                     open(out_csv, "w", newline="", encoding="utf-8-sig") as fout:
                    writer = csv.writer(fout)
                    writer.writerow(["device", "timestamp", "SpecDirName", "status", "detection_type"])
                    
                    fin.seek(0)
                    for line in fin:
                        parts = line.strip().split("~")
                        if len(parts) < 3: continue
                        
                        device, ts = parts[0], parts[1]
                        if not ts.startswith(target_date_str):
                            continue
                        
                        processed_lines += 1
                        try:
                            data = json.loads(parts[-2])
                        except json.JSONDecodeError: data = {}

                        keys_to_use = list(data.keys())
                        for key in keys_to_use:
                            spec_dir_name = data.get(key, {}).get("SpecDirName", "")
                            status = data.get(key, {}).get("status", "")
                            
                            config_value = DEVICE_CONFIG.get(device, "æœªçŸ¥")
                            if isinstance(config_value, str): detection_type = config_value
                            elif isinstance(config_value, dict): detection_type = config_value.get(spec_dir_name, "æœªçŸ¥")
                            else: detection_type = "æœªçŸ¥"
                                
                            writer.writerow([device, ts, spec_dir_name, status, detection_type])
                
                if processed_lines > 0:
                    if os.path.exists(out_txt): os.remove(out_txt)
                    os.rename(inp, out_txt)
                    print(f"âœ… [{ip}] å·²è¼¸å‡º ({processed_lines} ç­†è³‡æ–™):\n    - CSV: {out_csv}\n    - TXT: {out_txt}")
                else:
                    os.remove(out_csv)
                    print(f"â„¹ï¸ [{ip}] åœ¨ {fname} ä¸­æœªæ‰¾åˆ° {target_date_str} çš„è³‡æ–™ï¼Œå·²è·³éã€‚")

            except Exception as e:
                print(f"âŒ [{ip}] è§£ææª”æ¡ˆ {fname} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# ====== å‡½å¼é‡æ§‹ï¼šæ‹†åˆ†ç‚ºä¸‹è¼‰å’Œè™•ç† ======

def download_archive(ip):
    """éšæ®µä¸€ï¼šåªè² è²¬å¾å–®ä¸€IPä¸‹è¼‰æª”æ¡ˆï¼ŒæˆåŠŸå¾Œå›å‚³æª”æ¡ˆè·¯å¾‘ã€‚"""
    max_attempts = 2
    retry_delay = 60

    for attempt in range(max_attempts):
        driver = None
        try:
            print(f"ğŸ“¥ [{ip}] é–‹å§‹ä¸‹è¼‰ (ç¬¬ {attempt + 1} æ¬¡å˜—è©¦)...")
            driver = setup_driver()
            
            url = f"https://{USERNAME}:{PASSWORD}@{ip}/pixord/model/aidataexport_3dago.php"
            src = os.path.join(DOWNLOAD_DIR, "aidata.tar.gz")
            if os.path.exists(src): os.remove(src)
                
            driver.get(url)
            
            download_wait_timeout = 30
            wait_start_time = time.time()
            download_complete = False
            while time.time() - wait_start_time < download_wait_timeout:
                if os.path.exists(src):
                    time.sleep(1)
                    download_complete = True
                    break
                time.sleep(0.5)
            
            if not download_complete:
                raise Exception(f"ç­‰å¾…ä¸‹è¼‰é€¾æ™‚ ({download_wait_timeout}ç§’)")

            dst = os.path.join(DOWNLOAD_DIR, f"aidata_{ip.replace('.', '_')}_{run_date_str}.tar.gz")
            if os.path.exists(dst): os.remove(dst)
            os.rename(src, dst)
            print(f"âœ… [{ip}] ä¸‹è¼‰å®Œæˆï¼š{dst}")
            
            return dst # æˆåŠŸæ™‚å›å‚³æª”æ¡ˆè·¯å¾‘

        except Exception as e:
            print(f"âš ï¸ [{ip}] ç¬¬ {attempt + 1} æ¬¡å˜—è©¦ä¸‹è¼‰å¤±æ•—: {e}")
            if attempt < max_attempts - 1:
                print(f"â° [{ip}] ç­‰å¾… {retry_delay} ç§’å¾Œé‡è©¦â€¦")
                time.sleep(retry_delay)
            else:
                print(f"âŒ [{ip}] ä¸‹è¼‰é‡è©¦å¤±æ•—ï¼Œè·³éæ­¤ IPã€‚")
                return None # æœ€çµ‚å¤±æ•—æ™‚å›å‚³ None
        finally:
            if driver:
                driver.quit()

def process_downloaded_file(archive_path):
    """éšæ®µäºŒï¼šè™•ç†å–®ä¸€å·²ä¸‹è¼‰çš„å£“ç¸®æª”ã€‚"""
    if not archive_path:
        return

    # å¾æª”åä¸­è§£æå‡º IP ä½å€
    filename = os.path.basename(archive_path)
    match = re.search(r'aidata_(.*?)_\d{8}\.tar\.gz', filename)
    if not match:
        print(f"âŒ ç„¡æ³•å¾æª”å {filename} è§£æå‡º IP ä½å€ã€‚")
        return
        
    ip_with_underscores = match.group(1)
    ip = ip_with_underscores.replace('_', '.')
    
    print(f"âš™ï¸ [{ip}] é–‹å§‹è™•ç†æª”æ¡ˆï¼š{filename}")
    try:
        ext_dir = os.path.join(DOWNLOAD_DIR, f"{ip}_{run_date_str}")
        os.makedirs(ext_dir, exist_ok=True)
        with tarfile.open(archive_path, "r:gz") as t:
            t.extractall(ext_dir)
        print(f"ğŸ“‚ [{ip}] è§£å£“è‡³ï¼š{ext_dir}")
        
        process_logs(ext_dir, ip, data_date_str_for_filter, data_date_str_for_filename)
        print(f"âœ”ï¸ [{ip}] æª”æ¡ˆè™•ç†å®Œç•¢ã€‚")
    except Exception as e:
        print(f"âŒ [{ip}] è™•ç†æª”æ¡ˆ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# ====== ä¸»ç¨‹å¼ï¼šæ¡ç”¨å…©éšæ®µåŸ·è¡Œæµç¨‹ ======

if __name__ == "__main__":
    start_time = time.time()
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œè‡ªå‹•åŒ–è…³æœ¬ (åŸ·è¡Œæ—¥: {run_date}, è³‡æ–™æ—¥: {data_date})")

    # --- ç¬¬ä¸€éšæ®µï¼šå¹³è¡Œä¸‹è¼‰æ‰€æœ‰æª”æ¡ˆ ---
    print("\n===== éšæ®µä¸€ï¼šé–‹å§‹å¹³è¡Œä¸‹è¼‰æ‰€æœ‰æª”æ¡ˆ =====")
    downloaded_files = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_ip = {executor.submit(download_archive, ip): ip for ip in IPS}
        
        for future in as_completed(future_to_ip):
            result_path = future.result()
            if result_path: # å¦‚æœä¸‹è¼‰æˆåŠŸ (å›å‚³è·¯å¾‘)ï¼Œå°±åŠ å…¥æ¸…å–®
                downloaded_files.append(result_path)

    # --- ç¬¬äºŒéšæ®µï¼šå¾ªåºè™•ç†å·²ä¸‹è¼‰çš„æª”æ¡ˆ ---
    print(f"\n===== éšæ®µäºŒï¼šé–‹å§‹è™•ç† {len(downloaded_files)} å€‹å·²ä¸‹è¼‰çš„æª”æ¡ˆ =====")
    for archive_path in downloaded_files:
        process_downloaded_file(archive_path)
            
    end_time = time.time()
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼ç¸½è€—æ™‚: {end_time - start_time:.2f} ç§’")